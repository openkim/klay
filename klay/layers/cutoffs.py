from typing import Any

import torch

from ..core import ModuleCategory, register
from ._base import _BaseLayer


@torch.jit.script
def _poly_cutoff(x: torch.Tensor, factor: float, p: float = 6.0) -> torch.Tensor:
    x = x * factor

    out = 1.0
    out = out - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))
    out = out + (p * (p + 2.0) * torch.pow(x, p + 1.0))
    out = out - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))

    return out * (x < 1.0)


@register("PolynomialCutoff", inputs=["x"], outputs=["y"], category=ModuleCategory.EMBEDDING)
class PolynomialCutoff(_BaseLayer, torch.nn.Module):
    _factor: float
    p: float

    def __init__(self, r_max: float, p: float = 6):
        r"""Polynomial cutoff, as proposed in DimeNet: https://arxiv.org/abs/2003.03123


        Parameters
        ----------
        r_max : float
            Cutoff radius

        p : int
            Power used in envelope function
        """
        super().__init__()
        assert p >= 2.0
        self.p = float(p)
        self._factor = 1.0 / float(r_max)

    def forward(self, x):
        """
        Evaluate cutoff function.

        x: torch.Tensor, input distance
        """
        return _poly_cutoff(x, self._factor, p=self.p)

    @classmethod
    def from_config(cls, r_max: float, polynomial_degree: float = 6):
        """Create a new instance from the config.

        Args:
            r_max: Cutoff radius
            polynomial_degree: Power used in envelope function
        """
        return cls(r_max=r_max, p=polynomial_degree)
